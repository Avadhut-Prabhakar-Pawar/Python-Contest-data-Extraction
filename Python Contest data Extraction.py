# -*- coding: utf-8 -*-
"""Untitled4.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1jZ8sDZ4qths3lV0c69PrGsoIIRvS19CV
"""

import csv
import json
import time
from urllib.request import urlopen
from bs4 import BeautifulSoup

# Read country codes and ASINs from CSV file
with open('/content/drive/MyDrive/Amazon Scraping - Sheet1.csv', 'r') as f:
    reader = csv.reader(f)
    data = list(reader)

# Initialize results list
results = []

# Iterate over data in batches of 100
for i in range(0, len(data), 100):
    # Start timer
    start_time = time.time()

    # Iterate over current batch of data
    for row in data[i:i+100]:
        country_code = row[0]
        asin = row[1]

        # Construct URL
        url = f'https://www.amazon.{country_code}/dp/{asin}'

        try:
            # Open URL and parse HTML with BeautifulSoup
            html = urlopen(url)
            soup = BeautifulSoup(html, 'html.parser')

            # Scrape product title, image URL, price, and details
            title = soup.find('span', {'id': 'productTitle'}).text.strip()
            image_url = soup.find('img', {'id': 'landingImage'})['src']
            price = soup.find('span', {'id': 'priceblock_ourprice'}).text.strip()
            details = soup.find('div', {'id': 'feature-bullets'}).text.strip()

            # Append result to results list
            result = {
                'url': url,
                'title': title,
                'image_url': image_url,
                'price': price,
                'details': details
            }
            results.append(result)
        except:
            # Print error message if URL returns 404 error
            print(f'{url} not available')

    # Calculate time taken for current batch of 100 URLs
    time_taken = time.time() - start_time

    # Print time taken for current batch of 100 URLs
    print(f'Time taken for batch {i//100 + 1}: {time_taken:.2f} seconds')

# Write results to JSON file
with open('results.json', 'w') as f:
    json.dump(results, f)

!pip install twocaptcha
!pip install api

from twocaptcha import TwoCaptcha
import api

url = 'https://www.amazon.com/errors/validateCaptcha'

solver = TwoCaptcha(api.key)
result = solver.normal(url)
print(result['code'])